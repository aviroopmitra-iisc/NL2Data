## Goal

You are analyzing a real dataset and need to create an unstructured natural language description that could be used to generate synthetic data matching its characteristics. Your task is to generate a natural, flowing description written as GENERATION INSTRUCTIONS (not a description of existing data).

## Input Structure

The input will be provided as a single JSON file (DatasetIR) containing both the schema and generation specifications:

```
Dataset: {dataset_name}
Source: {source}
Rows: {num_rows}
Columns: {num_columns}

Schema:
{schema_text}

Generation Specifications (Distributions and Providers):
{generation_text}
```

The JSON structure contains:
- **logical**: Schema information with table structures, columns, types, constraints (primary keys, foreign keys, functional dependencies), and row counts
- **generation**: Distribution types and parameters for each column, plus any data providers (faker, mimesis, lookup)

Where:
- **Schema**: Contains table structures with columns, types, constraints (primary keys, foreign keys, functional dependencies), and row counts
- **Generation Specifications**: Contains distribution types and parameters for each column, plus any data providers (faker, mimesis, lookup)

## Output Structure

You must respond with a natural language description string that:
- Is written as GENERATION INSTRUCTIONS (imperative mood)
- Uses direct, action-oriented language ("Generate...", "Create...", "Include...", "Model...")
- Is 1-2 flowing paragraphs (prefer single paragraph when possible)
- Describes what to generate, not what exists

## Other Information

### Context

The dataset schema and generation specifications are provided in a single DatasetIR JSON file containing:
- **logical**: Complete relational schema with tables, columns, data types, primary keys, foreign keys, functional dependencies (stored per table in the `fds` field), and constraints
- **generation**: Distribution specifications for each column (uniform, normal, lognormal, zipf, categorical, etc.) and data providers where applicable

### Style Requirements

**CRITICAL STYLE REQUIREMENTS:**
- Write in 1-2 flowing paragraphs (prefer single paragraph when possible), similar to example dataset queries - be concise and direct
- Use simple, natural language - avoid technical statistical jargon (NO "Gini coefficient", "p-value", "shape parameter", "scale parameter", "KS statistic", "cardinality", "mean", "standard deviation", etc.)
- Describe distributions in plain terms:
  - "heavy-tailed" or "power-law distribution" for Pareto/Zipf
  - "right-skewed" for lognormal distributions
  - "most values are low with occasional high outliers" for skewed distributions
  - "follows a Zipf pattern where popular values appear frequently" for Zipf distributions
  - "uniformly distributed" for uniform distributions
  - "clustered around typical values" for normal distributions
- Focus on PATTERNS and BEHAVIORS, not individual column specifications - group similar columns together and describe patterns
- Avoid listing every column individually - instead describe types of columns and their general characteristics
- Use direct statements rather than "should" - e.g., "Numeric columns follow a right-skewed distribution" not "Numeric columns should follow..." - be direct and declarative
- Minimize use of "should", "must", "ensure" - instead state directly what the dataset contains or how it behaves
- Include approximate row count naturally within the text (e.g., "with approximately {num_rows} rows" or "containing about {num_rows} entries")
- Keep it practical and focused on what matters for generation - skip minor details and statistical minutiae
- Write as if briefly explaining to someone what dataset you need - natural, conversational, and direct
- Let it flow naturally - describe the dataset holistically rather than as a checklist of columns

### Distribution Interpretation

When you see distribution specifications, interpret them in natural language:
- **Uniform (range: [a, b])**: Values are evenly distributed across the range
- **Normal (mean: m, std: s)**: Values cluster around m with typical spread
- **Lognormal (mean: m, sigma: s)**: Right-skewed distribution, most values are low with some high outliers
- **Pareto (alpha: a, xm: x)**: Heavy-tailed distribution with extreme values
- **Zipf (exponent: s, domain size: n)**: Power-law distribution where popular values appear frequently
- **Categorical (values: [...])**: Discrete values from a specific set
- **Provider (e.g., faker.city)**: Realistic values generated by a data provider

### Examples

**Example 1:**
- Schema shows: Table "cities" with columns: city_id (INT, primary key), city_name (TEXT), country_code (TEXT, foreign key), population (INT)
- Generation shows: city_id uses Uniform, city_name uses faker.city provider, country_code uses lookup, population uses Categorical with specific values
- **Description**: "Generate a cities dataset with approximately 4000 entries. City names should be realistic place names. Populations follow a categorical distribution with values ranging from small towns to major metropolitan areas. Each city is linked to a country through country codes."

**Example 2:**
- Schema shows: Table "countries" with columns: country_code (TEXT, primary key), country_name (TEXT), population (INT), gnp (FLOAT)
- Generation shows: population uses Lognormal, gnp uses Lognormal
- **Description**: "Create a countries dataset with around 240 entries. Country populations and economic indicators (GNP) follow right-skewed distributions where most countries have moderate values, but a few have exceptionally high populations or economic output."

### Important Notes

- The description should read like a natural, concise instruction for generating a dataset - similar to how someone would briefly explain what they need in a conversation
- Focus on the overall patterns and key characteristics that matter, not exhaustive column-by-column details
- Mix domain context with key technical requirements naturally, but keep it simple and avoid statistical terminology
- Use present/future tense and imperative mood
- Aim for the style of example dataset queries: direct, flowing, pattern-focused, and practical
